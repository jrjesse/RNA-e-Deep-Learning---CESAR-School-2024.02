{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnkA6fazG2Eh"
   },
   "source": [
    "# PyTorch: Variable, Gradientes e Grafo Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdiT8nGeG2Ek"
   },
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDEX9Mk8G2Em"
   },
   "source": [
    "Este notebook introduz\n",
    "- o conceito de `Variables` do PyTorch,\n",
    "- uma interpretação numérica intuitiva do gradiente, e o\n",
    "- grafo computacional, utilizado para o cálculo automático do gradiente de uma função."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lPCM5vmG2Eo"
   },
   "source": [
    "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de\n",
    "calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada\n",
    "pelo tipo Variable do PyTorch, que adiciona ao tensor a facilidade de cálculo automático do gradiente pela construção dinâmica do grafo computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLATrVDrG2Eq"
   },
   "source": [
    "## Grafo computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbH9rnZmG2Er"
   },
   "source": [
    "```\n",
    "    y_pred = x * w\n",
    "    e = y_pred - y\n",
    "    e2 = e**2\n",
    "    J = e2.sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tPYkCldG2Es"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/vcasadei/images/master/GrafoComputacional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnTsPEf6G2Eu"
   },
   "source": [
    "Variable possui 3 campos: o dado em si (data), o gradiente (grad) e um apontador (creator) para construir o grafo da backpropagation. Uma expressão utilizada para o cálculo do gradiente exige que todas suas expressões sejam calculadas com Variables, caso contrário não é possível construir o grafo computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wI-LZc6G2Ev"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/vcasadei/images/master/variables.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.148492",
     "start_time": "2017-11-24T14:09:18.096752"
    },
    "id": "OJt_zc0CG2Ex"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JONBAEwzG2E4"
   },
   "source": [
    "## Variable é criada a partir de um tensor e possui as mesmas funcionalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.305082",
     "start_time": "2017-11-24T14:09:19.150032"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aT8CBLTaG2E6",
    "outputId": "09b51d1b-70ed-4bfd-ab44-243242f5acd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t = 2 * torch.arange(0.,4.) # Tensor: [0, 2, 4, 6]\n",
    "y = Variable(y_t); y # Transforma em Variable -> cálculo automático do gradiente pela construção do grafo computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.311537",
     "start_time": "2017-11-24T14:09:19.306712"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WiSNffiPG2FD",
    "outputId": "7d58c75f-3094-4cc7-a377-72c5c0c2ea27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.arange(0.,4.)); x # Tensor: [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.318102",
     "start_time": "2017-11-24T14:09:19.313131"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dW0pCsgaG2FK",
    "outputId": "a65902b9-608a-419d-a9e6-5184b56cca9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Variable(torch.ones(1),requires_grad=True); w # Escalar, inicializado em 1, com autograd ativado. É equivalente a declarar explicitamente Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRXfFM2TG2FR"
   },
   "source": [
    "## Cálculo automático do gradiente da função perda J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFuPZhFGG2FU"
   },
   "source": [
    "Seja a expressão: $$ J = ((x  w) - y)^2 $$\n",
    "\n",
    "Queremos calcular a derivada de $J$ em relação a $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqNof23cG2FW"
   },
   "source": [
    "### Montagem do grafo computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.344631",
     "start_time": "2017-11-24T14:09:19.319779"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71lXNZ9mG2FX",
    "outputId": "e745a280-0234-49eb-bc79-6d814ef8ff01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict (forward)\n",
    "y_pred = x * w # Predição: [0, 1, 2, 3] * w\n",
    "\n",
    "# cálculo da perda J: loss\n",
    "e = y_pred - y # Erro: predição - alvo\n",
    "e2 = e.pow(2)  # Erro quadrático\n",
    "J = e2.sum()   # Soma de quadrados -> função de custo (loss)\n",
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elNRuA34G2Fe"
   },
   "source": [
    "## Auto grad - processa o grafo computacional backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T15:55:45.308858",
     "start_time": "2017-10-04T15:55:45.304654"
    },
    "id": "y9mN5TqhG2Fm"
   },
   "source": [
    "O `backward()` varre o grafo computacional a partir da variável a ele associada e calcula o gradiente para todas as `Variables` que possuem o atributo `requires_grad` como verdadeiro.\n",
    "O `backward()` destroi o grafo após sua execução. Isso é intrínsico ao PyTorch pelo fato dele ser uma rede dinâmica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.355085",
     "start_time": "2017-11-24T14:09:19.346403"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrEXyjIDG2Fn",
    "outputId": "43ae91f3-c89a-4485-c559-bd5c588fcc1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-28.])\n"
     ]
    }
   ],
   "source": [
    "J.backward() # Aqui, o pytorch navega pelo grafo computacional e calcula a derivada de J em relação a w -> dJ/dw\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.363848",
     "start_time": "2017-11-24T14:09:19.356800"
    },
    "id": "MwkCb8LYG2Fu"
   },
   "outputs": [],
   "source": [
    "w.grad.data.zero_(); # Zera o gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9biEyEt1G2Fz"
   },
   "source": [
    "## Interpretação do Gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVaH2WFyG2F0"
   },
   "source": [
    "O gradiente de uma variável final (J) com respeito à outra variável de entrada (w) pode ser interpretado como o quanto a variável final J vai aumentar se houver um pequeno aumento na variável de entrada (w).\n",
    "Por exemplo suponha que o gradiente seja 28. Isto significa se aumentarmos a variável w de 0.001, então J vai aumentar de 0.028."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.372040",
     "start_time": "2017-11-24T14:09:19.365927"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnO_ImuHG2F2",
    "outputId": "004c0554-ba4d-4416-e536-258a80500d64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.9720, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.001\n",
    "y_pred = x * (w+eps)\n",
    "J_new = (y_pred - y).pow(2).sum() # Aproximação númerica do gradiente\n",
    "J_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.403233",
     "start_time": "2017-11-24T14:09:19.373831"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ObOY_GnG2F8",
    "outputId": "52e7c3ac-8e97-4a4e-dd27-f8e2ef9ceacd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.027988434\n"
     ]
    }
   ],
   "source": [
    "print((J_new - J).data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v625mnGlG2GC"
   },
   "source": [
    "## Back propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryb4BtcGG2GF"
   },
   "source": [
    "Uma forma equivalente explícita de calcular o gradiente é fazendo o processamento do backpropagation no grafo computacional, de forma explícita.\n",
    "Apenas como ilustração.\n",
    "\n",
    "Função de perda:\n",
    "$$ J(\\hat{y_i},y_i) = \\frac{1}{M} \\sum_{i=0}^{M-1} (\\hat{y_i} - y_i)^2 $$\n",
    "\n",
    "Gradiente:\n",
    "$$  \\mathbf{\\nabla{J_w}} = \\frac{2}{M}\\mathbf{x^T}(\\mathbf{x w^T} - \\mathbf{y}) $$\n",
    "\n",
    "Atualização dos parâmetros pelo gradiente descendente:\n",
    "$$ \\mathbf{w} = \\mathbf{w} − \\eta (\\mathbf{\\nabla J_w})^T $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.413681",
     "start_time": "2017-11-24T14:09:19.405014"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXrz6a0EG2GH",
    "outputId": "f046c029-f278-47fe-b6d7-cc6c1785c4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[1. 1. 1. 1.]\n",
      "[ 0. -2. -4. -6.]\n",
      "-28.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dJ = 1.                                  # dJ/dJ = 1\n",
    "de2 = dJ * np.ones((4,))                 # ∂J/∂e2_i = 1\n",
    "de = de2 * 2 * e.data.numpy()            # ∂e2_i/∂e_i = 2e_i\n",
    "dy_pred = de                             # ∂e_i/∂y_pred = 1\n",
    "dw = (dy_pred * x.data.numpy()).sum()    # Regra da cadeia\n",
    "print(dJ)\n",
    "print(de2)\n",
    "print(de)\n",
    "print(dw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pvsJc0tG2GR"
   },
   "source": [
    "## Visualizando o grafo computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jg-tSOvCMs1",
    "outputId": "4c1c00fb-0dc5-4a13-c524-c5a6e1e231a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.3)\n",
      "Collecting git+https://github.com/szagoruyko/pytorchviz\n",
      "  Cloning https://github.com/szagoruyko/pytorchviz to c:\\users\\mathe\\appdata\\local\\temp\\pip-req-build-hv8l0b5s\n",
      "  Resolved https://github.com/szagoruyko/pytorchviz to commit 5cf04c13e601366f6b9cf5939b5af5144d55b887\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchviz==0.0.2) (2.7.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchviz==0.0.2) (0.20.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchviz==0.0.2) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchviz==0.0.2) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchviz==0.0.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchviz==0.0.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchviz==0.0.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchviz==0.0.2) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->torchviz==0.0.2) (72.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch->torchviz==0.0.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->torchviz==0.0.2) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/szagoruyko/pytorchviz 'C:\\Users\\mathe\\AppData\\Local\\Temp\\pip-req-build-hv8l0b5s'\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "!pip install git+https://github.com/szagoruyko/pytorchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "VRZi7-urCZZS",
    "outputId": "ac890058-8ae4-4d79-ae3a-987b4c1d7aee"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"108pt\" height=\"394pt\"\n",
       " viewBox=\"0.00 0.00 108.00 394.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 390)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-390 104,-390 104,4 -4,4\"/>\n",
       "<!-- 2256067376496 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2256067376496</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77,-32.75 23,-32.75 23,0 77,0 77,-32.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 2256020949552 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2256020949552</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-89.5 6,-89.5 6,-68.75 94,-68.75 94,-89.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 2256020949552&#45;&gt;2256067376496 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2256020949552&#45;&gt;2256067376496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-68.36C50,-61.89 50,-53.05 50,-44.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-44.55 50,-34.55 46.5,-44.55 53.5,-44.55\"/>\n",
       "</g>\n",
       "<!-- 2256065494224 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2256065494224</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-146.25 6,-146.25 6,-125.5 94,-125.5 94,-146.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 2256065494224&#45;&gt;2256020949552 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2256065494224&#45;&gt;2256020949552</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-125.09C50,-118.47 50,-109.47 50,-101.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-101.34 50,-91.34 46.5,-101.34 53.5,-101.34\"/>\n",
       "</g>\n",
       "<!-- 2256065816288 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2256065816288</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-203 6,-203 6,-182.25 94,-182.25 94,-203\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 2256065816288&#45;&gt;2256065494224 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2256065816288&#45;&gt;2256065494224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-181.84C50,-175.22 50,-166.22 50,-158.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-158.09 50,-148.09 46.5,-158.09 53.5,-158.09\"/>\n",
       "</g>\n",
       "<!-- 2256065818160 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2256065818160</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-259.75 6,-259.75 6,-239 94,-239 94,-259.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 2256065818160&#45;&gt;2256065816288 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2256065818160&#45;&gt;2256065816288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-238.59C50,-231.97 50,-222.97 50,-214.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-214.84 50,-204.84 46.5,-214.84 53.5,-214.84\"/>\n",
       "</g>\n",
       "<!-- 2256065817344 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2256065817344</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-316.5 0,-316.5 0,-295.75 100,-295.75 100,-316.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-303\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2256065817344&#45;&gt;2256065818160 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2256065817344&#45;&gt;2256065818160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-295.34C50,-288.72 50,-279.72 50,-271.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-271.59 50,-261.59 46.5,-271.59 53.5,-271.59\"/>\n",
       "</g>\n",
       "<!-- 2256065553792 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2256065553792</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77,-386 23,-386 23,-352.5 77,-352.5 77,-386\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-372.5\" font-family=\"monospace\" font-size=\"10.00\">w</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-359.75\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 2256065553792&#45;&gt;2256065817344 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2256065553792&#45;&gt;2256065817344</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-352.19C50,-344.85 50,-336.07 50,-328.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-328.48 50,-318.48 46.5,-328.48 53.5,-328.48\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x20d47fb76b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot, make_dot_from_trace\n",
    "J = ((w * x) - y).pow(2).sum()\n",
    "p = {'w':w} # dicionário de parâmetros\n",
    "out = make_dot(J,params=p)      # Gera o grafo computacional que mostra todas as operações feitas e como elas dependem de w\n",
    "out  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "bIqUBct4G2Gg",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEfWG-e5G2Gh"
   },
   "source": [
    "## Questões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXLoZzF6G2Gj"
   },
   "source": [
    "1. Por que numa expressão computacional não é possível misturar `Variable` com tensores?\n",
    "- Variable é um tipo especial que armazena um grafo computacional, enquanto tensor é apenas um tipo de dado, tal qual um array, por exemplo.\n",
    "2. O que acontece com o grafo computacional após execução do `backward()`?\n",
    "- Após chamar backward(), como foi feito acima com J.backward(), o pytorch libera o grafo computacional por padrão para economizar memória.\n",
    "\n",
    "Referências:\n",
    "- https://discuss.pytorch.org/t/what-is-the-difference-between-tensors-and-variables-in-pytorch/4914/2\n",
    "- https://sebarnold.net/tutorials/beginner/examples_autograd/two_layer_net_autograd.html\n",
    "- https://docs.pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
    "- https://medium.com/biased-algorithms/what-does-the-backward-function-do-8d8e535afa9d#:~:text=By%20default%2C%20backward()%20frees,in%20memory%20for%20further%20use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayWukpAIG2Gk"
   },
   "source": [
    "## Atividades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-06T22:02:17.474843Z",
     "start_time": "2017-10-06T22:02:17.468865Z"
    },
    "id": "k5Ayt5dAG2Gl"
   },
   "source": [
    "1. Execute um passo de atualização do valor de w, pelo\n",
    "gradiente descendente. Utilize um fator de aprendizado (*learning rate*) de 0.1\n",
    "para atualizar o `w`. Após, recalcule a função de perda:\n",
    "\n",
    "    - w = w - lr * w.grad.data\n",
    "    - execute a célula 1.3.1 e verifique o quanto que a perda J diminuiu\n",
    "    \n",
    "2. No trecho abaixo, uma rede bastante conhecida, `resnet18` contendo 18 camadas\n",
    "   é criada, tendo\n",
    "   como entrada `xin` que é convertida para `Variable`, resultando na saída `y`.\n",
    "   \n",
    "   Descomente a linha que cria a vizualização do grafo computacional e execute a\n",
    "   célula para visualizar o grafo computacional da rede `resnet18`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J antes da atualização: 14.0\n",
      "Novo valor de w: 3.799999952316284\n",
      "J depois da atualização: 45.35999298095703\n"
     ]
    }
   ],
   "source": [
    "# Atividade 1\n",
    "x = Variable(torch.arange(0., 4.))\n",
    "y = Variable(2 * torch.arange(0., 4.))  # y = [0, 2, 4, 6]\n",
    "w = Variable(torch.ones(1), requires_grad=True)  # w = 1\n",
    "\n",
    "y_pred = x * w\n",
    "J = ((y_pred - y).pow(2)).sum()  # função de custo\n",
    "print(\"J antes da atualização:\", J.item())\n",
    "\n",
    "J.backward()\n",
    "\n",
    "lr = 0.1\n",
    "w.data = w.data - lr * w.grad.data  # atualiza w\n",
    "print(\"Novo valor de w:\", w.item())\n",
    "\n",
    "w.grad.data.zero_()\n",
    "\n",
    "y_pred = x * w\n",
    "J_novo = ((y_pred - y).pow(2)).sum()\n",
    "print(\"J depois da atualização:\", J_novo.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:09:19.519949",
     "start_time": "2017-11-24T16:09:18.148Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKwW1oQ8G2Go",
    "outputId": "4a442e65-d051-4307-b66c-8d5a6ab05425",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: torch==2.7.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.7.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.7.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.7.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.7.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.7.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.7.0->torchvision) (72.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch==2.7.0->torchvision) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "from torchvision import models\n",
    "xin = torch.randn(1,3,224,224)\n",
    "resnet18 = models.resnet18()\n",
    "y = resnet18(Variable(xin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"62pt\" height=\"41pt\"\n",
       " viewBox=\"0.00 0.00 62.00 40.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 36.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-36.75 58,-36.75 58,4 -4,4\"/>\n",
       "<!-- 2256067399264 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2256067399264</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"54,-32.75 0,-32.75 0,0 54,0 54,-32.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> (4)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x20d480073b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Atividade 2\n",
    "g = make_dot(y, dict(resnet18.named_parameters()))\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S6srVMzG2G1"
   },
   "source": [
    "# Aprendizados com este notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "VyUo4FaAG2G2",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "No começo do notebook, o foco era entender como o gradiente é calculado com o tipo Variable. Foi feito o seguinte:\n",
    "1. Montamos a função de perda J(w)\n",
    "2. Usamos J.backward() para obter o gradiente\n",
    "3. Imprimimos w.grad, mas não alteramos w\n",
    "4. Também foi feita uma validação numérica desse gradiente via diferença finita, e foi mostrado o grafo computacional\n",
    "\n",
    "Conclusão: Estávamos apenas analisando o comportamento da função e seu gradiente, sem modificar os parâmetros.\n",
    "\n",
    "Na atividade 1, entramos com o processo de aprendizado da seguinte forma:\n",
    "1. Calculamos o gradiente como antes\n",
    "2. Usamos o resultado do gradiente para atualizar w\n",
    "3. Recalculamos a função de custo J(w) com o novo valor de w\n",
    "\n",
    "Conclusão: Isso simula o processo real de uma rede neural -> ajustar os parâmetros para minimizar a perda com base no gradiente.\n",
    "\n",
    "Em suma, o grande aprendizado desse notebook foi chegar no mesmo resultado que chegamos nos notebooks anteriores, porém de maneira mais direta com outros tipos do pytorch, que abstraem muitos cálculos que eram feitos de forma mais explícita utilizando o numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2.4-PyTorch_Variaveis_Gradientes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fe3e6f0cdaab8afdc61c52912fda83f7c0a71baaea1897dd7498e2df01e69ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
